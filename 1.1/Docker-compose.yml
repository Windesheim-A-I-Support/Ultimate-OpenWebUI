version: "3.9"

volumes:
  openwebui_data:
  pipelines_data:
  ollama_models:

services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    restart: unless-stopped
    ports:
      - "3000:8080"
    environment:
      ENABLE_PERSISTENT_CONFIG: "true"
      # behind reverse proxy; trust X-Forwarded-* headers
      TRUSTED_PROXY: "*"
      # Providers
      OPENAI_API_BASE_URL: http://pipelines:9099/v1
      OPENAI_API_KEY: ${PIPELINES_API_KEY:-0p3n-w3bu!}
      OLLAMA_BASE_URL: http://ollama:11434
    volumes:
      - openwebui_data:/app/backend/data
    depends_on:
      pipelines:
        condition: service_started
      ollama:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 15
      start_period: 10s

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: pipelines
    restart: unless-stopped
    environment:
      PIPELINES_PASSWORD: ${PIPELINES_API_KEY:-0p3n-w3bu!}
    volumes:
      - pipelines_data:/app/pipelines
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:9099 >/dev/null || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 15
      start_period: 10s

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    volumes:
      - ollama_models:/root/.ollama
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 3s
      retries: 15
      start_period: 10s
